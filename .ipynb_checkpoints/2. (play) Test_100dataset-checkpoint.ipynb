{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 좌표값으로 MET 값 예측\n",
    "14개의 좌표(x,y)값을 활용하여 MET 값을 예측해보기 \n",
    "\n",
    "Data : 100개 <br>\n",
    "좌표 개수 : 14개\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## --------------------------------------------------------------------------------------\n",
    "## Data 구조 처리\n",
    "학습용으로 사용하기 위한 이미지 데이터와 좌푯값 전처리 코드.\n",
    "\n",
    "CSV 구성 형식\n",
    "- 이미지 경로 , 관절좌표1, 관절좌표2, ... , 관절좌표14, MET Score\n",
    "\n",
    "처리 형식\n",
    "- 전체 데이터세트 이미지 최대 크기와 평균 크기 측정 -> 이미지 크기 조정\n",
    "  크기 조정 비율에 따른 좌표값 재처리\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # Numpy 배열 사용용도\n",
    "import matplotlib.pyplot as plt # 이미지출력 용도\n",
    "import pandas as pd # csv 파일을 pandas 프레임으로 호출 용도\n",
    "import skimage\n",
    "from skimage import io, transform # 이미지 불러오기 및 저장용도\n",
    "\n",
    "# 주피터 노트북 상에 이미지를 출력하도록 설정\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기존의 Data Set 구조 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['/var/data/MET/images/walking/20.bmp', '[17, 146]', '[23, 115]',\n",
       "        ..., '[40, 39]', '[35, 17]', 0.7],\n",
       "       ['/var/data/MET/images/walking/19.bmp', '[22, 129]', '[12, 116]',\n",
       "        ..., '[21, 38]', '[14, 16]', 0.7],\n",
       "       ['/var/data/MET/images/walking/18.bmp', '[23, 153]', '[21, 129]',\n",
       "        ..., '[23, 41]', '[20, 21]', 0.7],\n",
       "       ..., \n",
       "       [ '/var/data/MET/images/miscellaneous occupational activity/machine work.sawing/18.jpg',\n",
       "        '[-1, -1]', '[-1, -1]', ..., '[175, 61]', '[192, 1]', 1.8],\n",
       "       [ '/var/data/MET/images/miscellaneous occupational activity/machine work.sawing/19.jpg',\n",
       "        '[-1, -1]', '[98, 170]', ..., '[172, 59]', '[201, 8]', 1.8],\n",
       "       [ '/var/data/MET/images/miscellaneous occupational activity/machine work.sawing/20.jpg',\n",
       "        '[-1, -1]', '[-1, -1]', ..., '[194, 55]', '[185, 8]', 1.8]], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset CSV 파일을 불러와 pandas 프레임으로 저장한 뒤에 Numpy형식의 행렬로 변환하여 testset 변수에 저장\n",
    "testset=pd.read_csv(\"/home/ejjchl77/predictMET/dataset.csv\",header=None).as_matrix()\n",
    "\n",
    "testset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "100장의 Data에 (저장위치, 좌표, MET값):16개 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 16)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "221.51 243.43 769 834\n"
     ]
    }
   ],
   "source": [
    "# 변수 초기화.\n",
    "# 모든 x축 크기 총합, 모든 y축 크기 총합, 최대 x축 크기, 최대 y축 크기\n",
    "allsum_x=allsum_y=max_x=max_y=0\n",
    "\n",
    "for i in range(len(testset)): # testset 길이만큼 반복 // len(testset) = 100개 데이터\n",
    "    img=skimage.io.imread(testset[i][0]) # 이미지 불러오기 (이미지 저장위치 불러오기)\n",
    "    # img.shape의 구조는 \"행렬의 rows, columns, channels의 갯수\"\n",
    "    \n",
    "    if max_x<img.shape[0]: max_x=img.shape[0] # 최대 x축 길이값 저장\n",
    "    if max_y<img.shape[1]: max_y=img.shape[1] # 최대 y축 길이값 저장\n",
    "    allsum_x+=img.shape[0] # 모든 이미지의 x축 크기 총합\n",
    "    allsum_y+=img.shape[1] # 모든 이미지의 y축 크기 총합\n",
    "avg_x=allsum_x/len(testset) # 전체 이미지의 x축 크기 평균\n",
    "avg_y=allsum_y/len(testset) # 전체 이미지의 y축 크기 평균\n",
    "print (avg_x,avg_y,max_x,max_y) # x축 크기 평균, y축 크기 평균, 최대 x축 크기, 최대 y축 크기 출력\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "평균 : (x,y) =(221.51, 243.43)\n",
    "\n",
    "이미지 크기를 256 x 256 으로 조정\n",
    "\n",
    "#### 기존 Data Set에서 좌표만 따로 저장 => Trainig input값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문자열의 좌표값을 정수형 좌표값으로 변환하는 함수\n",
    "def convert_str_to_int(coors):\n",
    "    coor=np.zeros([len(coors),14,2],dtype=int) # 변환한 좌표를 저장하기 위한 배열 초기화\n",
    "    for i in range(len(coors)): # 주어진 갯수 만큼 반복\n",
    "        for j in range(14): # 좌표 개수 만큼 반복\n",
    "            a=0 # 컴마 위치 확인용\n",
    "            # \",\" 위치 체크\n",
    "            while True: # 무한 반복문\n",
    "                if coors[i][j+1][a]==\",\" : break # 해당 문자가 컴마면 무한 반복문 탈출\n",
    "                else : a+=1 # 컴마가 아니면 다음 문자로 넘어감\n",
    "            # ,를 기준으로 각각의 좌표 x y를 나누어 int로 형변환 하여 저장\n",
    "            coor[i][j]=int(coors[i][j+1][1:a]),int(coors[i][j+1][a+1:-1])\n",
    "            \n",
    "    # 이렇게 반복하여 추출한 좌표값을 반환\n",
    "    return coor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 기존 Data Set에서 MET만 따로 저장 => 결과값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.7]\n",
      " [ 0.7]\n",
      " [ 0.7]\n",
      " [ 0.7]\n",
      " [ 0.7]\n",
      " [ 0.7]\n",
      " [ 0.7]\n",
      " [ 0.7]\n",
      " [ 0.7]\n",
      " [ 0.7]\n",
      " [ 0.7]\n",
      " [ 0.7]\n",
      " [ 0.7]\n",
      " [ 0.7]\n",
      " [ 0.7]\n",
      " [ 0.7]\n",
      " [ 0.7]\n",
      " [ 0.7]\n",
      " [ 0.7]\n",
      " [ 0.7]\n",
      " [ 1. ]\n",
      " [ 1. ]\n",
      " [ 1. ]\n",
      " [ 1. ]\n",
      " [ 1. ]\n",
      " [ 1. ]\n",
      " [ 1. ]\n",
      " [ 1. ]\n",
      " [ 1. ]\n",
      " [ 1. ]\n",
      " [ 1. ]\n",
      " [ 1. ]\n",
      " [ 1. ]\n",
      " [ 1. ]\n",
      " [ 1. ]\n",
      " [ 1. ]\n",
      " [ 1. ]\n",
      " [ 1. ]\n",
      " [ 1. ]\n",
      " [ 1. ]\n",
      " [ 1.2]\n",
      " [ 1.2]\n",
      " [ 1.2]\n",
      " [ 1.2]\n",
      " [ 1.2]\n",
      " [ 1.2]\n",
      " [ 1.2]\n",
      " [ 1.2]\n",
      " [ 1.2]\n",
      " [ 1.2]\n",
      " [ 1.2]\n",
      " [ 1.2]\n",
      " [ 1.2]\n",
      " [ 1.2]\n",
      " [ 1.2]\n",
      " [ 1.2]\n",
      " [ 1.2]\n",
      " [ 1.2]\n",
      " [ 1.2]\n",
      " [ 1.2]\n",
      " [ 1.2]\n",
      " [ 1.2]\n",
      " [ 1.2]\n",
      " [ 1.2]\n",
      " [ 1.2]\n",
      " [ 1.2]\n",
      " [ 1.2]\n",
      " [ 1.2]\n",
      " [ 1.2]\n",
      " [ 1.2]\n",
      " [ 1.2]\n",
      " [ 1.2]\n",
      " [ 1.2]\n",
      " [ 1.2]\n",
      " [ 1.2]\n",
      " [ 1.2]\n",
      " [ 1.2]\n",
      " [ 1.2]\n",
      " [ 1.2]\n",
      " [ 1.2]\n",
      " [ 1.8]\n",
      " [ 1.8]\n",
      " [ 1.8]\n",
      " [ 1.8]\n",
      " [ 1.8]\n",
      " [ 1.8]\n",
      " [ 1.8]\n",
      " [ 1.8]\n",
      " [ 1.8]\n",
      " [ 1.8]\n",
      " [ 1.8]\n",
      " [ 1.8]\n",
      " [ 1.8]\n",
      " [ 1.8]\n",
      " [ 1.8]\n",
      " [ 1.8]\n",
      " [ 1.8]\n",
      " [ 1.8]\n",
      " [ 1.8]\n",
      " [ 1.8]]\n"
     ]
    }
   ],
   "source": [
    "def convert2_str_to_float(dataset):\n",
    "    MET=np.zeros([len(dataset),1],dtype=float) # 변환한 좌표를 저장하기 위한 배열 초기화\n",
    "    for i in range(len(dataset)): # 주어진 갯수 만큼 반복\n",
    "        MET[i]=float(dataset[i][15])\n",
    "       \n",
    "    # 이렇게 반복하여 추출한 좌표값을 반환\n",
    "    return MET\n",
    "\n",
    "MET = convert2_str_to_float(testset)\n",
    "print(MET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "구조파악을 위한 식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(176, 79, 3)\n",
      "(100, 14, 2)\n",
      "[ 17 146]\n",
      "[ 23 115]\n",
      "17\n",
      "24.7272727273\n"
     ]
    }
   ],
   "source": [
    "img=skimage.io.imread(testset[0][0])\n",
    "print(img.shape)\n",
    "coor_set=convert_str_to_int(testset)\n",
    "print(coor_set.shape)\n",
    "print(coor_set[0][0])\n",
    "print(coor_set[0][1])\n",
    "print(coor_set[0][0][0])\n",
    "print(coor_set[0][0][0]*(256/img.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 따로 뽑아낸 좌표를 이미지 크기에 맞게 조정해줌 : 전처리 작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Preprocess(dataset):\n",
    "    img_set=np.zeros([len(dataset),256,256,3]) \n",
    "    # 이미지를 저장해두기 위한 텐서 배열 초기화 - 이미지 갯수 / x크기 / y크기 / RGB\n",
    "    \n",
    "    coor_set=convert_str_to_int(dataset) \n",
    "    # 문자열의 좌표값을 정수형 좌표값으로 변환하여 저장\n",
    "    \n",
    "    for i in range(len(dataset)): # 주어진 데이터 갯수만큼 반복\n",
    "        img=skimage.io.imread(dataset[i][0]) # 이미지 불러오기\n",
    "        \n",
    "        img_set[i]=skimage.transform.resize(img,(256,256)) \n",
    "        # 이미지 크기를 재조정 하여 저장\n",
    "        \n",
    "        #이미지 크기 변환을 하였으므로 그에 걸맞게 좌표 위치또한 재조정\n",
    "        for j in range(14): #주어진 좌표 개수 만큼 반복\n",
    "            if coor_set[i][j][0]==-1: coor_set[i][j][0]=-1 \n",
    "                # x 좌표 값이 -1 이면 조정을 해주지 않음\n",
    "            else: coor_set[i][j][0]=coor_set[i][j][0]*(256/img.shape[1]) \n",
    "                # x축 크기의 변환된 비율 만큼 곱해 Scaling \n",
    "            if coor_set[i][j][1]==-1: coor_set[i][j][1]=-1 # y 좌표 값이 -1 이면 조정을 해주지 않음\n",
    "            else: coor_set[i][j][1]=coor_set[i][j][1]*(256/img.shape[0]) # y축 크기의 변환된 비율 만큼 곱해 Scaling \n",
    "    \n",
    "    # 이렇게 변환한 이미지 세트와 좌표 세트를 반환\n",
    "    return img_set, coor_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "coco : 좌표값 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ejjchl77/eunjivenv/lib/python3.5/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    }
   ],
   "source": [
    "# 전처리 함수의 입력으로 불러온 CSV 파일을 저장한 testset 변수로 입력.\n",
    "# 변환된 이미지 세트와 좌표 세트를 각각 picpic과 coco에다 저장해줌.\n",
    "picpic,coco=Preprocess(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 256, 256, 3) (100, 14, 2)\n"
     ]
    }
   ],
   "source": [
    "# 각 세트의 크기 확인\n",
    "print (picpic.shape,coco.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지와 좌표를 받아와서 이미에 해당 좌표를 입력\n",
    "# 잘 변환이 되었는지 확인하는 용도\n",
    "\n",
    "import cv2 # 그림에 숫자 넣기\n",
    "from skimage import draw # 그림에 원 그리기\n",
    "\n",
    "def markJoints(img, joints):  \n",
    "    circSize=5 # 그려질 원의 크기\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX # 글씨체 설정\n",
    "    for i in range(14):\n",
    "        x = int(joints[i,0]) # X 좌표\n",
    "        y = int(joints[i,1]) # Y 좌표\n",
    "        if x!=-1: # 그림에서 보이지 않는 좌표는 찍지 않도록\n",
    "            rr, cc = skimage.draw.circle(y, x, circSize) # 원 그리기  `skimage.draw.circle(r, c, 반지름[shape])`\n",
    "            skimage.draw.set_color(img, (rr, cc), (1,0,0)) # 색 설정 `set_color(image, coords, color)`\n",
    "            cv2.putText(img, str(i+1), (x,y), font, 0.5, (0.5,0.5,0.5), 2, cv2.LINE_AA) # 그림 ㄱ\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imge = np.zeros((10,10), dtype=np.uint8)\n",
    "#rr, cc = circle(4,4,5)\n",
    "#imge[rr, cc]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘p_img’: File exists\r\n",
      "mkdir: cannot create directory ‘p_with_coors_img’: File exists\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ejjchl77/eunjivenv/lib/python3.5/site-packages/skimage/util/dtype.py:122: UserWarning: Possible precision loss when converting from float64 to uint8\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n"
     ]
    }
   ],
   "source": [
    "# 전처리된 이미지 저장\n",
    "%mkdir p_img p_with_coors_img # 현재 디렉토리에 처리된 이미지와 좌표를 찍은 이미지들을 저장할 디렉토리 생성\n",
    "for i in range(len(picpic)):\n",
    "    skimage.io.imsave(\"./p_img/p-img_\"+str(i)+\".jpg\",picpic[i]) # 처리된 이미지 저장\n",
    "    skimage.io.imsave(\"./p_with_coors_img/p-img_\"+str(i)+\".jpg\",markJoints(picpic[i],coco[i])) # 좌표 입력 이미지 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"training_linear_models\"\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True):\n",
    "    path = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID, fig_id + \".png\")\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format='png', dpi=300)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 좌표 데이터 구조 변환 (100,14,2) -> (100,28)  \n",
    "\n",
    "기존 : [[x1, y1], [x2, y2], $\\cdots$, [x14, y14]]\n",
    "\n",
    "변경 : [x1, y1, x2, y2 ..., x14, y14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 55, 212,  74, ...,  56, 113,  24],\n",
       "       [ 93, 190,  51, ...,  56,  59,  23],\n",
       "       [101, 217,  92, ...,  58,  88,  29],\n",
       "       ..., \n",
       "       [ -1,  -1,  -1, ...,  57, 164,   0],\n",
       "       [ -1,  -1,  63, ...,  62, 130,   8],\n",
       "       [ -1,  -1,  -1, ...,  42, 152,   6]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coco=np.reshape(coco,(100,28))\n",
    "coco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.7],\n",
       "       [ 0.7],\n",
       "       [ 0.7],\n",
       "       [ 0.7],\n",
       "       [ 0.7],\n",
       "       [ 0.7],\n",
       "       [ 0.7],\n",
       "       [ 0.7],\n",
       "       [ 0.7],\n",
       "       [ 0.7],\n",
       "       [ 0.7],\n",
       "       [ 0.7],\n",
       "       [ 0.7],\n",
       "       [ 0.7],\n",
       "       [ 0.7],\n",
       "       [ 0.7],\n",
       "       [ 0.7],\n",
       "       [ 0.7],\n",
       "       [ 0.7],\n",
       "       [ 0.7],\n",
       "       [ 1. ],\n",
       "       [ 1. ],\n",
       "       [ 1. ],\n",
       "       [ 1. ],\n",
       "       [ 1. ],\n",
       "       [ 1. ],\n",
       "       [ 1. ],\n",
       "       [ 1. ],\n",
       "       [ 1. ],\n",
       "       [ 1. ],\n",
       "       [ 1. ],\n",
       "       [ 1. ],\n",
       "       [ 1. ],\n",
       "       [ 1. ],\n",
       "       [ 1. ],\n",
       "       [ 1. ],\n",
       "       [ 1. ],\n",
       "       [ 1. ],\n",
       "       [ 1. ],\n",
       "       [ 1. ],\n",
       "       [ 1.2],\n",
       "       [ 1.2],\n",
       "       [ 1.2],\n",
       "       [ 1.2],\n",
       "       [ 1.2],\n",
       "       [ 1.2],\n",
       "       [ 1.2],\n",
       "       [ 1.2],\n",
       "       [ 1.2],\n",
       "       [ 1.2],\n",
       "       [ 1.2],\n",
       "       [ 1.2],\n",
       "       [ 1.2],\n",
       "       [ 1.2],\n",
       "       [ 1.2],\n",
       "       [ 1.2],\n",
       "       [ 1.2],\n",
       "       [ 1.2],\n",
       "       [ 1.2],\n",
       "       [ 1.2],\n",
       "       [ 1.2],\n",
       "       [ 1.2],\n",
       "       [ 1.2],\n",
       "       [ 1.2],\n",
       "       [ 1.2],\n",
       "       [ 1.2],\n",
       "       [ 1.2],\n",
       "       [ 1.2],\n",
       "       [ 1.2],\n",
       "       [ 1.2],\n",
       "       [ 1.2],\n",
       "       [ 1.2],\n",
       "       [ 1.2],\n",
       "       [ 1.2],\n",
       "       [ 1.2],\n",
       "       [ 1.2],\n",
       "       [ 1.2],\n",
       "       [ 1.2],\n",
       "       [ 1.2],\n",
       "       [ 1.2],\n",
       "       [ 1.8],\n",
       "       [ 1.8],\n",
       "       [ 1.8],\n",
       "       [ 1.8],\n",
       "       [ 1.8],\n",
       "       [ 1.8],\n",
       "       [ 1.8],\n",
       "       [ 1.8],\n",
       "       [ 1.8],\n",
       "       [ 1.8],\n",
       "       [ 1.8],\n",
       "       [ 1.8],\n",
       "       [ 1.8],\n",
       "       [ 1.8],\n",
       "       [ 1.8],\n",
       "       [ 1.8],\n",
       "       [ 1.8],\n",
       "       [ 1.8],\n",
       "       [ 1.8],\n",
       "       [ 1.8]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 100개의 좌표값과 MET데이터 중 10개를 test데이터로 사용하기 위해 추출 \n",
    "    MET값의 중복을 피하기위해 (0, 10, 20, 30, 40, $\\cdots$, 100)번째의 좌표 및 MET값을 Test값으로 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=0;b=0\n",
    "coco_train=np.zeros([90,28])\n",
    "MET_train=np.zeros([90,1])\n",
    "coco_test=np.zeros([10,28])\n",
    "MET_test=np.zeros([10,1])\n",
    "\n",
    "for i in range (100):\n",
    "    if i % 10 == 0:\n",
    "        coco_test[a]=coco[i]\n",
    "        MET_test[a]=MET[i]\n",
    "        a+=1\n",
    "    else :\n",
    "        coco_train[b]=coco[i]\n",
    "        MET_train[b]=MET[i]\n",
    "        b+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.7],\n",
       "       [ 0.7],\n",
       "       [ 1. ],\n",
       "       [ 1. ],\n",
       "       [ 1.2],\n",
       "       [ 1.2],\n",
       "       [ 1.2],\n",
       "       [ 1.2],\n",
       "       [ 1.8],\n",
       "       [ 1.8]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MET_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal Equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=tf.placeholder(tf.float32, shape=[None, 28])\n",
    "Y=tf.placeholder(tf.float32, shape=[None, 1])\n",
    "w=tf.Variable(tf.random_normal([28,1]), name='weight')\n",
    "b=tf.Variable(tf.random_normal([1]), name='bias')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis=tf.matmul(X,w)+b\n",
    "cost=tf.reduce_mean(tf.square(hypothesis-Y))\n",
    "\n",
    "optimizer=tf.train.GradientDescentOptimizer(learning_rate=1e-5)\n",
    "train=optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_b = np.c_[np.ones((100, 1)), coco]  # add x0 = 1 to each instance\n",
    "theta_best = np.linalg.inv(X_b.T.dot(X_b)).dot(X_b.T).dot(MET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1.32554299]),\n",
       " array([[  9.81473262e-04,  -1.31981868e-03,  -2.48180814e-03,\n",
       "           1.11351536e-03,   8.55150762e-04,  -1.28847674e-03,\n",
       "          -1.00155038e-03,   2.29202113e-03,   1.40736435e-03,\n",
       "          -1.95626547e-03,   9.04141842e-04,  -6.96280801e-04,\n",
       "           7.57432273e-04,  -3.37373486e-04,   2.27710651e-03,\n",
       "          -1.78510490e-04,  -6.92755158e-04,  -1.72643444e-04,\n",
       "           3.71454295e-04,  -5.09212737e-03,  -2.96399183e-06,\n",
       "           1.27724884e-04,  -4.59606132e-05,   1.42334697e-03,\n",
       "          -9.37737028e-04,   4.80047730e-04,   1.78687719e-04,\n",
       "           3.94785848e-03]]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(coco_train, MET_train)\n",
    "lin_reg.intercept_, lin_reg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**score: 결정계수(coefficient of determination,R^2)를 보여줌, 독립적인 변수들로 부터의 분산 비율**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39656911947210083"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg.score(coco_train,MET_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.097023759606756022"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg.score(coco_test,MET_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.95956193],\n",
       "       [ 1.05750781],\n",
       "       [ 0.96811226],\n",
       "       [ 0.7308875 ],\n",
       "       [ 0.92192878],\n",
       "       [ 1.75912466],\n",
       "       [ 0.93470436],\n",
       "       [ 1.03555068],\n",
       "       [ 1.60127246],\n",
       "       [ 1.18781324]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg.predict(coco_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Conclusion\n",
    "\n",
    "값이 좋진 않지만 어느정도 일정 범주에서 MET 값이 예측\n",
    "\n",
    "데이터가 더 필요할 것으로 예상"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. SDG regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_path_sgd = []\n",
    "m = len(X_b)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "sgd_reg = SGDRegressor(max_iter=50, penalty=None, eta0=0.1, random_state=42)\n",
    "#sgd_reg.fit(X, y.ravel())\n",
    "sgd_reg.fit(coco_train, MET_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_reg.intercept_, sgd_reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_reg.predict(coco_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_reg.score(coco_train,MET_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_reg.score(coco_test,MET_test.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly_features = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_poly = poly_features.fit_transform(coco_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_poly[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_poly, MET_train)\n",
    "lin_reg.intercept_, lin_reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg.predict(coco_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial Regression Conclusion\n",
    "\n",
    "오류발생으로 해결 못한 상태"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. MLPRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neural_network import MLPRegressor \n",
    "\n",
    "X = coco_train\n",
    "y = MET_train.astype(np.float)\n",
    "\n",
    "per_clf = MLPRegressor(random_state=42, activation=\"relu\", solver=\"adam\")\n",
    "per_clf.fit(X, y)\n",
    "\n",
    "y_pred = per_clf.predict(coco_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MET_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_clf.intercepts_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "per_clf.coefs_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_clf.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_clf.score(coco_test,MET_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "n_inputs = 28 \n",
    "n_hidden1 = 300\n",
    "n_hidden2 = 100\n",
    "n_outputs = 1     #MET값 1개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.get_shape()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neuron_layer(X, n_neurons, name, activation=None):\n",
    "    with tf.name_scope(name):\n",
    "        n_inputs = int(X.get_shape()[1])\n",
    "        stddev = 2 / np.sqrt(n_inputs)\n",
    "        init = tf.truncated_normal((n_inputs, n_neurons), stddev=stddev)\n",
    "        W = tf.Variable(init, name=\"kernel\")\n",
    "        b = tf.Variable(tf.zeros([n_neurons], dtype=tf.float32), name=\"bias\")\n",
    "        Z = tf.matmul(X, W) + b\n",
    "        if activation is not None:\n",
    "            return activation(Z)\n",
    "        else:\n",
    "            return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"dnn\"):\n",
    "    hidden1 = neuron_layer(X, n_hidden1, name=\"hidden1\",\n",
    "                           activation=tf.nn.relu)\n",
    "    hidden2 = neuron_layer(hidden1, n_hidden2, name=\"hidden2\",\n",
    "                           activation=tf.nn.relu)\n",
    "    logits = neuron_layer(hidden2, n_outputs, name=\"outputs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    #xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y,\n",
    "    #                                                          logits=logits)\n",
    "    loss = tf.losses.mean_squared_error(y, logits)\n",
    "    #loss = -tf.reduce_sum(logits * tf.log(p))\n",
    "    #loss = tf.reduce_mean(xentropy, name=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with tf.name_scope(\"eval\"):\n",
    "#    correct = tf.nn.in_top_k(logits, y, 1)  -> 위에서부터 가장 큰 값만 찾는건 라벨링 된 이미지 처리할때\n",
    "#    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        sess.run(training_op, feed_dict={X: coco_train, y: MET_train})\n",
    "        #acc_train = accuracy.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "        #acc_val = accuracy.eval(feed_dict={X: mnist.validation.images,\n",
    "        #                                    y: mnist.validation.labels})\n",
    "        print(epoch, \"loss :\", loss)\n",
    "\n",
    "    save_path = saver.save(sess, \"./dnn0319.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, \"./my_model_final.ckpt\") # or better, use save_path\n",
    "    X_new_scaled = coco_test\n",
    "    y_pred = logits.eval(feed_dict={X: X_new_scaled})\n",
    "    #y_pred = np.argmax(Z, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Predicted classes:\", y_pred)\n",
    "print(\"Actual classes:   \", MET_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TensorFlow conclusion (현재 진행 상황)\n",
    "    \n",
    "DNN 학습할때, 기존 MNIST 처럼 이미지 label 분류가 아닌 MET 값을 도출해야 해서\n",
    "\n",
    "Loss는 softmax가 아닌 mean_square_error를 사용 -> Loss값 보는 방법 개선 필요..\n",
    "\n",
    "correct와 accuracy 부분은 아직 해결책을 못찾음\n",
    "\n",
    "결과적으로 값으로 예측하기는 실패"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
