{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "221.51 243.43 769 834\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # Numpy 배열 사용용도\n",
    "import matplotlib.pyplot as plt # 이미지출력 용도\n",
    "import pandas as pd # csv 파일을 pandas 프레임으로 호출 용도\n",
    "import skimage\n",
    "from skimage import io, transform # 이미지 불러오기 및 저장용도\n",
    "\n",
    "# 주피터 노트북 상에 이미지를 출력하도록 설정\n",
    "%matplotlib inline\n",
    "\n",
    "# dataset CSV 파일을 불러와 pandas 프레임으로 저장한 뒤에 Numpy형식의 행렬로 변환하여 testset 변수에 저장\n",
    "testset=pd.read_csv(\"/home/ejjchl77/predictMET/dataset.csv\",header=None).as_matrix()\n",
    "\n",
    "# 변수 초기화.\n",
    "# 모든 x축 크기 총합, 모든 y축 크기 총합, 최대 x축 크기, 최대 y축 크기\n",
    "allsum_x=allsum_y=max_x=max_y=0\n",
    "\n",
    "for i in range(len(testset)): # testset 길이만큼 반복 // len(testset) = 100개 데이터\n",
    "    img=skimage.io.imread(testset[i][0]) # 이미지 불러오기 (이미지 저장위치 불러오기)\n",
    "    # img.shape의 구조는 \"행렬의 rows, columns, channels의 갯수\"\n",
    "    \n",
    "    if max_x<img.shape[0]: max_x=img.shape[0] # 최대 x축 길이값 저장\n",
    "    if max_y<img.shape[1]: max_y=img.shape[1] # 최대 y축 길이값 저장\n",
    "    allsum_x+=img.shape[0] # 모든 이미지의 x축 크기 총합\n",
    "    allsum_y+=img.shape[1] # 모든 이미지의 y축 크기 총합\n",
    "avg_x=allsum_x/len(testset) # 전체 이미지의 x축 크기 평균\n",
    "avg_y=allsum_y/len(testset) # 전체 이미지의 y축 크기 평균\n",
    "\n",
    "print (avg_x,avg_y,max_x,max_y) # x축 크기 평균, y축 크기 평균, 최대 x축 크기, 최대 y축 크기 출력\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문자열의 좌표값을 정수형 좌표값으로 변환하는 함수\n",
    "def convert_str_to_int(coors):\n",
    "    coor=np.zeros([len(coors),14,2],dtype=int) # 변환한 좌표를 저장하기 위한 배열 초기화\n",
    "    for i in range(len(coors)): # 주어진 갯수 만큼 반복\n",
    "        for j in range(14): # 좌표 개수 만큼 반복\n",
    "            a=0 # 컴마 위치 확인용\n",
    "            # \",\" 위치 체크\n",
    "            while True: # 무한 반복문\n",
    "                if coors[i][j+1][a]==\",\" : break # 해당 문자가 컴마면 무한 반복문 탈출\n",
    "                else : a+=1 # 컴마가 아니면 다음 문자로 넘어감\n",
    "            # ,를 기준으로 각각의 좌표 x y를 나누어 int로 형변환 하여 저장\n",
    "            coor[i][j]=int(coors[i][j+1][1:a]),int(coors[i][j+1][a+1:-1])\n",
    "            \n",
    "    # 이렇게 반복하여 추출한 좌표값을 반환\n",
    "    return coor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ejjchl77/eunjivenv/lib/python3.5/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    }
   ],
   "source": [
    "def Preprocess(dataset):\n",
    "    img_set=np.zeros([len(dataset),256,256,3]) \n",
    "    # 이미지를 저장해두기 위한 텐서 배열 초기화 - 이미지 갯수 / x크기 / y크기 / RGB\n",
    "    \n",
    "    coor_set=convert_str_to_int(dataset) \n",
    "    # 문자열의 좌표값을 정수형 좌표값으로 변환하여 저장\n",
    "    \n",
    "    for i in range(len(dataset)): # 주어진 데이터 갯수만큼 반복\n",
    "        img=skimage.io.imread(dataset[i][0]) # 이미지 불러오기\n",
    "        \n",
    "        img_set[i]=skimage.transform.resize(img,(256,256)) \n",
    "        # 이미지 크기를 재조정 하여 저장\n",
    "        \n",
    "        #이미지 크기 변환을 하였으므로 그에 걸맞게 좌표 위치또한 재조정\n",
    "        for j in range(14): #주어진 좌표 개수 만큼 반복\n",
    "            if coor_set[i][j][0]==-1: coor_set[i][j][0]=-1 \n",
    "                # x 좌표 값이 -1 이면 조정을 해주지 않음\n",
    "            else: coor_set[i][j][0]=coor_set[i][j][0]*(256/img.shape[1]) \n",
    "                # x축 크기의 변환된 비율 만큼 곱해 Scaling \n",
    "            if coor_set[i][j][1]==-1: coor_set[i][j][1]=-1 # y 좌표 값이 -1 이면 조정을 해주지 않음\n",
    "            else: coor_set[i][j][1]=coor_set[i][j][1]*(256/img.shape[0]) # y축 크기의 변환된 비율 만큼 곱해 Scaling \n",
    "    \n",
    "    # 이렇게 변환한 이미지 세트와 좌표 세트를 반환\n",
    "    return img_set, coor_set\n",
    "\n",
    "picpic,coco=Preprocess(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지와 좌표를 받아와서 이미에 해당 좌표를 입력\n",
    "# 잘 변환이 되었는지 확인하는 용도\n",
    "\n",
    "import cv2 # 그림에 숫자 넣기\n",
    "from skimage import draw # 그림에 원 그리기\n",
    "\n",
    "def markJoints(img, joints):  \n",
    "    circSize=5 # 그려질 원의 크기\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX # 글씨체 설정\n",
    "    for i in range(14):\n",
    "        x = int(joints[i,0]) # X 좌표\n",
    "        y = int(joints[i,1]) # Y 좌표\n",
    "        if x!=-1: # 그림에서 보이지 않는 좌표는 찍지 않도록\n",
    "            rr, cc = skimage.draw.circle(y, x, circSize) # 원 그리기  `skimage.draw.circle(r, c, 반지름[shape])`\n",
    "            skimage.draw.set_color(img, (rr, cc), (1,0,0)) # 색 설정 `set_color(image, coords, color)`\n",
    "            cv2.putText(img, str(i+1), (x,y), font, 0.5, (0.5,0.5,0.5), 2, cv2.LINE_AA) # 그림 ㄱ\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘p_img’: File exists\r\n",
      "mkdir: cannot create directory ‘p_with_coors_img’: File exists\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ejjchl77/eunjivenv/lib/python3.5/site-packages/skimage/util/dtype.py:122: UserWarning: Possible precision loss when converting from float64 to uint8\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n"
     ]
    }
   ],
   "source": [
    "# 전처리된 이미지 저장\n",
    "%mkdir p_img p_with_coors_img # 현재 디렉토리에 처리된 이미지와 좌표를 찍은 이미지들을 저장할 디렉토리 생성\n",
    "for i in range(len(picpic)):\n",
    "    skimage.io.imsave(\"./p_img/p-img_\"+str(i)+\".jpg\",picpic[i]) # 처리된 이미지 저장\n",
    "    skimage.io.imsave(\"./p_with_coors_img/p-img_\"+str(i)+\".jpg\",markJoints(picpic[i],coco[i])) # 좌표 입력 이미지 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classfication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.7]\n",
      " [ 0.7]\n",
      " [ 0.7]\n",
      " [ 0.7]\n",
      " [ 0.7]\n",
      " [ 0.7]\n",
      " [ 0.7]\n",
      " [ 0.7]\n",
      " [ 0.7]\n",
      " [ 0.7]\n",
      " [ 0.7]\n",
      " [ 0.7]\n",
      " [ 0.7]\n",
      " [ 0.7]\n",
      " [ 0.7]\n",
      " [ 0.7]\n",
      " [ 0.7]\n",
      " [ 0.7]\n",
      " [ 0.7]\n",
      " [ 0.7]\n",
      " [ 1. ]\n",
      " [ 1. ]\n",
      " [ 1. ]\n",
      " [ 1. ]\n",
      " [ 1. ]\n",
      " [ 1. ]\n",
      " [ 1. ]\n",
      " [ 1. ]\n",
      " [ 1. ]\n",
      " [ 1. ]\n",
      " [ 1. ]\n",
      " [ 1. ]\n",
      " [ 1. ]\n",
      " [ 1. ]\n",
      " [ 1. ]\n",
      " [ 1. ]\n",
      " [ 1. ]\n",
      " [ 1. ]\n",
      " [ 1. ]\n",
      " [ 1. ]\n",
      " [ 1.2]\n",
      " [ 1.2]\n",
      " [ 1.2]\n",
      " [ 1.2]\n",
      " [ 1.2]\n",
      " [ 1.2]\n",
      " [ 1.2]\n",
      " [ 1.2]\n",
      " [ 1.2]\n",
      " [ 1.2]\n",
      " [ 1.2]\n",
      " [ 1.2]\n",
      " [ 1.2]\n",
      " [ 1.2]\n",
      " [ 1.2]\n",
      " [ 1.2]\n",
      " [ 1.2]\n",
      " [ 1.2]\n",
      " [ 1.2]\n",
      " [ 1.2]\n",
      " [ 1.2]\n",
      " [ 1.2]\n",
      " [ 1.2]\n",
      " [ 1.2]\n",
      " [ 1.2]\n",
      " [ 1.2]\n",
      " [ 1.2]\n",
      " [ 1.2]\n",
      " [ 1.2]\n",
      " [ 1.2]\n",
      " [ 1.2]\n",
      " [ 1.2]\n",
      " [ 1.2]\n",
      " [ 1.2]\n",
      " [ 1.2]\n",
      " [ 1.2]\n",
      " [ 1.2]\n",
      " [ 1.2]\n",
      " [ 1.2]\n",
      " [ 1.2]\n",
      " [ 1.8]\n",
      " [ 1.8]\n",
      " [ 1.8]\n",
      " [ 1.8]\n",
      " [ 1.8]\n",
      " [ 1.8]\n",
      " [ 1.8]\n",
      " [ 1.8]\n",
      " [ 1.8]\n",
      " [ 1.8]\n",
      " [ 1.8]\n",
      " [ 1.8]\n",
      " [ 1.8]\n",
      " [ 1.8]\n",
      " [ 1.8]\n",
      " [ 1.8]\n",
      " [ 1.8]\n",
      " [ 1.8]\n",
      " [ 1.8]\n",
      " [ 1.8]]\n"
     ]
    }
   ],
   "source": [
    "def convert2_str_to_float(dataset):\n",
    "    MET=np.zeros([len(dataset),1],dtype=float) # 변환한 좌표를 저장하기 위한 배열 초기화\n",
    "    for i in range(len(dataset)): # 주어진 갯수 만큼 반복\n",
    "        MET[i]=float(dataset[i][15])\n",
    "       \n",
    "    # 이렇게 반복하여 추출한 좌표값을 반환\n",
    "    return MET\n",
    "\n",
    "MET = convert2_str_to_float(testset)\n",
    "print(MET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0\n",
      "0   0.0\n",
      "1   0.0\n",
      "2   0.0\n",
      "3   0.0\n",
      "4   0.0\n",
      "5   0.0\n",
      "6   0.0\n",
      "7   0.0\n",
      "8   0.0\n",
      "9   0.0\n",
      "10  0.0\n",
      "11  0.0\n",
      "12  0.0\n",
      "13  0.0\n",
      "14  0.0\n",
      "15  0.0\n",
      "16  0.0\n",
      "17  0.0\n",
      "18  0.0\n",
      "19  0.0\n",
      "20  1.0\n",
      "21  1.0\n",
      "22  1.0\n",
      "23  1.0\n",
      "24  1.0\n",
      "25  1.0\n",
      "26  1.0\n",
      "27  1.0\n",
      "28  1.0\n",
      "29  1.0\n",
      "..  ...\n",
      "70  3.0\n",
      "71  3.0\n",
      "72  3.0\n",
      "73  3.0\n",
      "74  3.0\n",
      "75  3.0\n",
      "76  3.0\n",
      "77  3.0\n",
      "78  3.0\n",
      "79  3.0\n",
      "80  4.0\n",
      "81  4.0\n",
      "82  4.0\n",
      "83  4.0\n",
      "84  4.0\n",
      "85  4.0\n",
      "86  4.0\n",
      "87  4.0\n",
      "88  4.0\n",
      "89  4.0\n",
      "90  4.0\n",
      "91  4.0\n",
      "92  4.0\n",
      "93  4.0\n",
      "94  4.0\n",
      "95  4.0\n",
      "96  4.0\n",
      "97  4.0\n",
      "98  4.0\n",
      "99  4.0\n",
      "\n",
      "[100 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "from pandas import Series, DataFrame\n",
    "MET=DataFrame(MET)\n",
    "\n",
    "MET.loc[0:20]=0\n",
    "MET.loc[20:40]=1\n",
    "MET.loc[40:60]=2\n",
    "MET.loc[60:80]=3\n",
    "MET.loc[80:100]=4\n",
    "\n",
    "MET.astype=(int)\n",
    "print(MET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco = np.reshape(coco,(100,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=0;b=0\n",
    "coco_train=np.zeros([90,28])\n",
    "MET_train=np.zeros([90,1])\n",
    "coco_test=np.zeros([10,28])\n",
    "MET_test=np.zeros([10,1])\n",
    "\n",
    "for i in range (100):\n",
    "    if i % 10 == 0:\n",
    "        coco_test[a]=coco[i]\n",
    "        MET_test[a]=MET.loc[i]\n",
    "        a+=1\n",
    "    else :\n",
    "        coco_train[b]=coco[i]\n",
    "        MET_train[b]=MET.loc[i]\n",
    "        b+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- sigmoid 함수 사용\n",
    "- DNN Layer1 28x28 // Layer2 28x1\n",
    "- LR : 0.1\n",
    "- loss : cross entrophy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "x_data=coco_train\n",
    "y_data=MET_train\n",
    "\n",
    "nb_class=5\n",
    "\n",
    "X=tf.placeholder(tf.float32,[None,28])\n",
    "Y=tf.placeholder(tf.int32,[None,1])\n",
    "\n",
    "Y_one_hot=tf.one_hot(Y, nb_class)\n",
    "Y_one_hot=tf.reshape(Y_one_hot,[-1, nb_class])\n",
    "\n",
    "W1=tf.Variable(tf.random_normal([28, 10]), name='weight1')\n",
    "b1=tf.Variable(tf.random_normal([10]), name='bias1')\n",
    "layer1 = tf.nn.softmax(tf.matmul(X,W1)+b1)\n",
    "\n",
    "\n",
    "W2=tf.Variable(tf.random_normal([10,nb_class], name='weight2'))\n",
    "b2=tf.Variable(tf.random_normal([nb_class]), name='bias2')\n",
    "hypothesis=tf.nn.softmax(tf.matmul(layer1,W2)+b2)\n",
    "#logit=tf.matmul(layer1,W2)+b2\n",
    "#hypothesis=tf.nn.sigmoid(tf.matmul(layer1,W2)+b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-23-c8595eb48c05>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-23-c8595eb48c05>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#cost=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logit, labels=Y_one_hot))\n",
    "cost=tf.reduce_mean(-tf.reduce_sum(Y*tf.log(hypothesis), axis=1)\n",
    "#cost=tf.reduce_sum(-tf.reduce_sum(Y*tf.log(hypothesis)+(1-Y)*tf.log(1-hypothesis)))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=tf.argmax(hypothesis,1)\n",
    "correct_prediction=tf.equal(prediction, tf.argmax(Y_one_hot,1))\n",
    "accuracy=tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import sys\n",
    "orig_stdout=sys.stdout\n",
    "f=open('output.xls','w')\n",
    "sys.stdout=f'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "#    for epoch in range(training_epochs):\n",
    "    for step in range(500000):\n",
    "        sess.run(optimizer, feed_dict={X:x_data, Y:y_data})\n",
    "        if step%10000==0:\n",
    "            loss, acc = sess.run([cost, accuracy], feed_dict={X:x_data, Y:y_data})\n",
    "            print(\"Step: {:5}\\t Loss: {:.3f}\\t Accuracy: {:.2%}\".format(step,loss,acc))\n",
    "            \n",
    "    #pred = sess.run(prediction, feed_dict={X:x_data})\n",
    "    #for p,y in zip(pred, y_data.flatten()):\n",
    "    #    print(\"[{}] Prediction:{} True Y:{}\".format(p==int(y),pred,int(y)))\n",
    "    \n",
    "    print(\"-\"*100)\n",
    "    \n",
    "    # predict\n",
    "    int_MET=tf.to_int32(MET_test)\n",
    "    Actual_MET=tf.reshape(int_MET,[10])\n",
    "    print(\"Actual    :\", sess.run(Actual_MET))\n",
    "    print(\"Prediction:\", sess.run(prediction, feed_dict={X:coco_test}))\n",
    "\n",
    "    # Calculate the accuracy\n",
    "    print(\"Accuracy:\", sess.run(accuracy, feed_dict={X:coco_test, Y:MET_test}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sys.stdout=orig_stdout\n",
    "#f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
